{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ya_-3PQNO_Hb"
   },
   "source": [
    "#1.Data Exploration and Preprocessing                    \n",
    "●\tBegin by loading and exploring the \"Alphabets_data.csv\" dataset. Summarize its key features such as the number of samples, features, and classes.           \n",
    "●\tExecute necessary data preprocessing steps including data normalization, managing missing values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "yAyOKAoHL-My",
    "outputId": "84e1b7fc-7bf3-48de-d7b7-4fda9ba092a1"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>letter</th>\n",
       "      <th>xbox</th>\n",
       "      <th>ybox</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>onpix</th>\n",
       "      <th>xbar</th>\n",
       "      <th>ybar</th>\n",
       "      <th>x2bar</th>\n",
       "      <th>y2bar</th>\n",
       "      <th>xybar</th>\n",
       "      <th>x2ybar</th>\n",
       "      <th>xy2bar</th>\n",
       "      <th>xedge</th>\n",
       "      <th>xedgey</th>\n",
       "      <th>yedge</th>\n",
       "      <th>yedgex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>T</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>D</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>N</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>G</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19995</th>\n",
       "      <td>D</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19996</th>\n",
       "      <td>C</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>12</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19997</th>\n",
       "      <td>T</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19998</th>\n",
       "      <td>S</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19999</th>\n",
       "      <td>A</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20000 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      letter  xbox  ybox  width  height  onpix  xbar  ybar  x2bar  y2bar  \\\n",
       "0          T     2     8      3       5      1     8    13      0      6   \n",
       "1          I     5    12      3       7      2    10     5      5      4   \n",
       "2          D     4    11      6       8      6    10     6      2      6   \n",
       "3          N     7    11      6       6      3     5     9      4      6   \n",
       "4          G     2     1      3       1      1     8     6      6      6   \n",
       "...      ...   ...   ...    ...     ...    ...   ...   ...    ...    ...   \n",
       "19995      D     2     2      3       3      2     7     7      7      6   \n",
       "19996      C     7    10      8       8      4     4     8      6      9   \n",
       "19997      T     6     9      6       7      5     6    11      3      7   \n",
       "19998      S     2     3      4       2      1     8     7      2      6   \n",
       "19999      A     4     9      6       6      2     9     5      3      1   \n",
       "\n",
       "       xybar  x2ybar  xy2bar  xedge  xedgey  yedge  yedgex  \n",
       "0          6      10       8      0       8      0       8  \n",
       "1         13       3       9      2       8      4      10  \n",
       "2         10       3       7      3       7      3       9  \n",
       "3          4       4      10      6      10      2       8  \n",
       "4          6       5       9      1       7      5      10  \n",
       "...      ...     ...     ...    ...     ...    ...     ...  \n",
       "19995      6       6       4      2       8      3       7  \n",
       "19996     12       9      13      2       9      3       7  \n",
       "19997     11       9       5      2      12      2       4  \n",
       "19998     10       6       8      1       9      5       8  \n",
       "19999      8       1       8      2       7      2       8  \n",
       "\n",
       "[20000 rows x 17 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load the dataset\n",
    "Alphabets_df = pd.read_csv('Alphabets_data.csv')\n",
    "\n",
    "Alphabets_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RzsLmkt1RO-a",
    "outputId": "27ec3ef4-70e3-40ad-ff1e-36dc2310373c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20000 entries, 0 to 19999\n",
      "Data columns (total 17 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   letter  20000 non-null  object\n",
      " 1   xbox    20000 non-null  int64 \n",
      " 2   ybox    20000 non-null  int64 \n",
      " 3   width   20000 non-null  int64 \n",
      " 4   height  20000 non-null  int64 \n",
      " 5   onpix   20000 non-null  int64 \n",
      " 6   xbar    20000 non-null  int64 \n",
      " 7   ybar    20000 non-null  int64 \n",
      " 8   x2bar   20000 non-null  int64 \n",
      " 9   y2bar   20000 non-null  int64 \n",
      " 10  xybar   20000 non-null  int64 \n",
      " 11  x2ybar  20000 non-null  int64 \n",
      " 12  xy2bar  20000 non-null  int64 \n",
      " 13  xedge   20000 non-null  int64 \n",
      " 14  xedgey  20000 non-null  int64 \n",
      " 15  yedge   20000 non-null  int64 \n",
      " 16  yedgex  20000 non-null  int64 \n",
      "dtypes: int64(16), object(1)\n",
      "memory usage: 2.6+ MB\n"
     ]
    }
   ],
   "source": [
    "Alphabets_df.info() # Display basic Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 320
    },
    "id": "ezF-R0GqRkox",
    "outputId": "13a383d6-d46b-4095-a541-d87b9b58d85e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>xbox</th>\n",
       "      <th>ybox</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>onpix</th>\n",
       "      <th>xbar</th>\n",
       "      <th>ybar</th>\n",
       "      <th>x2bar</th>\n",
       "      <th>y2bar</th>\n",
       "      <th>xybar</th>\n",
       "      <th>x2ybar</th>\n",
       "      <th>xy2bar</th>\n",
       "      <th>xedge</th>\n",
       "      <th>xedgey</th>\n",
       "      <th>yedge</th>\n",
       "      <th>yedgex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>20000.000000</td>\n",
       "      <td>20000.000000</td>\n",
       "      <td>20000.000000</td>\n",
       "      <td>20000.00000</td>\n",
       "      <td>20000.000000</td>\n",
       "      <td>20000.000000</td>\n",
       "      <td>20000.000000</td>\n",
       "      <td>20000.000000</td>\n",
       "      <td>20000.000000</td>\n",
       "      <td>20000.000000</td>\n",
       "      <td>20000.00000</td>\n",
       "      <td>20000.000000</td>\n",
       "      <td>20000.000000</td>\n",
       "      <td>20000.000000</td>\n",
       "      <td>20000.000000</td>\n",
       "      <td>20000.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.023550</td>\n",
       "      <td>7.035500</td>\n",
       "      <td>5.121850</td>\n",
       "      <td>5.37245</td>\n",
       "      <td>3.505850</td>\n",
       "      <td>6.897600</td>\n",
       "      <td>7.500450</td>\n",
       "      <td>4.628600</td>\n",
       "      <td>5.178650</td>\n",
       "      <td>8.282050</td>\n",
       "      <td>6.45400</td>\n",
       "      <td>7.929000</td>\n",
       "      <td>3.046100</td>\n",
       "      <td>8.338850</td>\n",
       "      <td>3.691750</td>\n",
       "      <td>7.80120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.913212</td>\n",
       "      <td>3.304555</td>\n",
       "      <td>2.014573</td>\n",
       "      <td>2.26139</td>\n",
       "      <td>2.190458</td>\n",
       "      <td>2.026035</td>\n",
       "      <td>2.325354</td>\n",
       "      <td>2.699968</td>\n",
       "      <td>2.380823</td>\n",
       "      <td>2.488475</td>\n",
       "      <td>2.63107</td>\n",
       "      <td>2.080619</td>\n",
       "      <td>2.332541</td>\n",
       "      <td>1.546722</td>\n",
       "      <td>2.567073</td>\n",
       "      <td>1.61747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.00000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>5.00000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>7.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>6.00000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.00000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>8.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>7.00000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>8.00000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>9.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>15.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>15.00000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>15.00000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>15.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               xbox          ybox         width       height         onpix  \\\n",
       "count  20000.000000  20000.000000  20000.000000  20000.00000  20000.000000   \n",
       "mean       4.023550      7.035500      5.121850      5.37245      3.505850   \n",
       "std        1.913212      3.304555      2.014573      2.26139      2.190458   \n",
       "min        0.000000      0.000000      0.000000      0.00000      0.000000   \n",
       "25%        3.000000      5.000000      4.000000      4.00000      2.000000   \n",
       "50%        4.000000      7.000000      5.000000      6.00000      3.000000   \n",
       "75%        5.000000      9.000000      6.000000      7.00000      5.000000   \n",
       "max       15.000000     15.000000     15.000000     15.00000     15.000000   \n",
       "\n",
       "               xbar          ybar         x2bar         y2bar         xybar  \\\n",
       "count  20000.000000  20000.000000  20000.000000  20000.000000  20000.000000   \n",
       "mean       6.897600      7.500450      4.628600      5.178650      8.282050   \n",
       "std        2.026035      2.325354      2.699968      2.380823      2.488475   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        6.000000      6.000000      3.000000      4.000000      7.000000   \n",
       "50%        7.000000      7.000000      4.000000      5.000000      8.000000   \n",
       "75%        8.000000      9.000000      6.000000      7.000000     10.000000   \n",
       "max       15.000000     15.000000     15.000000     15.000000     15.000000   \n",
       "\n",
       "            x2ybar        xy2bar         xedge        xedgey         yedge  \\\n",
       "count  20000.00000  20000.000000  20000.000000  20000.000000  20000.000000   \n",
       "mean       6.45400      7.929000      3.046100      8.338850      3.691750   \n",
       "std        2.63107      2.080619      2.332541      1.546722      2.567073   \n",
       "min        0.00000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        5.00000      7.000000      1.000000      8.000000      2.000000   \n",
       "50%        6.00000      8.000000      3.000000      8.000000      3.000000   \n",
       "75%        8.00000      9.000000      4.000000      9.000000      5.000000   \n",
       "max       15.00000     15.000000     15.000000     15.000000     15.000000   \n",
       "\n",
       "            yedgex  \n",
       "count  20000.00000  \n",
       "mean       7.80120  \n",
       "std        1.61747  \n",
       "min        0.00000  \n",
       "25%        7.00000  \n",
       "50%        8.00000  \n",
       "75%        9.00000  \n",
       "max       15.00000  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Alphabets_df.describe() # Display Statistical Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 226
    },
    "id": "SBgt3KlvSFjG",
    "outputId": "0e6db5d5-0b2f-4c4b-b0d5-643b83752231"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Pooja\\AppData\\Local\\Temp\\ipykernel_4656\\1887860129.py:6: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[0.13333333 0.33333333 0.26666667 ... 0.4        0.13333333 0.26666667]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  normalized_data.iloc[:, 1:] = scaler.fit_transform(Alphabets_df.iloc[:, 1:])\n",
      "C:\\Users\\Pooja\\AppData\\Local\\Temp\\ipykernel_4656\\1887860129.py:6: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[0.53333333 0.8        0.73333333 ... 0.6        0.2        0.6       ]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  normalized_data.iloc[:, 1:] = scaler.fit_transform(Alphabets_df.iloc[:, 1:])\n",
      "C:\\Users\\Pooja\\AppData\\Local\\Temp\\ipykernel_4656\\1887860129.py:6: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[0.2        0.2        0.4        ... 0.4        0.26666667 0.4       ]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  normalized_data.iloc[:, 1:] = scaler.fit_transform(Alphabets_df.iloc[:, 1:])\n",
      "C:\\Users\\Pooja\\AppData\\Local\\Temp\\ipykernel_4656\\1887860129.py:6: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[0.33333333 0.46666667 0.53333333 ... 0.46666667 0.13333333 0.4       ]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  normalized_data.iloc[:, 1:] = scaler.fit_transform(Alphabets_df.iloc[:, 1:])\n",
      "C:\\Users\\Pooja\\AppData\\Local\\Temp\\ipykernel_4656\\1887860129.py:6: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[0.06666667 0.13333333 0.4        ... 0.33333333 0.06666667 0.13333333]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  normalized_data.iloc[:, 1:] = scaler.fit_transform(Alphabets_df.iloc[:, 1:])\n",
      "C:\\Users\\Pooja\\AppData\\Local\\Temp\\ipykernel_4656\\1887860129.py:6: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[0.53333333 0.66666667 0.66666667 ... 0.4        0.53333333 0.6       ]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  normalized_data.iloc[:, 1:] = scaler.fit_transform(Alphabets_df.iloc[:, 1:])\n",
      "C:\\Users\\Pooja\\AppData\\Local\\Temp\\ipykernel_4656\\1887860129.py:6: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[0.86666667 0.33333333 0.4        ... 0.73333333 0.46666667 0.33333333]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  normalized_data.iloc[:, 1:] = scaler.fit_transform(Alphabets_df.iloc[:, 1:])\n",
      "C:\\Users\\Pooja\\AppData\\Local\\Temp\\ipykernel_4656\\1887860129.py:6: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[0.         0.33333333 0.13333333 ... 0.2        0.13333333 0.2       ]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  normalized_data.iloc[:, 1:] = scaler.fit_transform(Alphabets_df.iloc[:, 1:])\n",
      "C:\\Users\\Pooja\\AppData\\Local\\Temp\\ipykernel_4656\\1887860129.py:6: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[0.4        0.26666667 0.4        ... 0.46666667 0.4        0.06666667]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  normalized_data.iloc[:, 1:] = scaler.fit_transform(Alphabets_df.iloc[:, 1:])\n",
      "C:\\Users\\Pooja\\AppData\\Local\\Temp\\ipykernel_4656\\1887860129.py:6: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[0.4        0.86666667 0.66666667 ... 0.73333333 0.66666667 0.53333333]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  normalized_data.iloc[:, 1:] = scaler.fit_transform(Alphabets_df.iloc[:, 1:])\n",
      "C:\\Users\\Pooja\\AppData\\Local\\Temp\\ipykernel_4656\\1887860129.py:6: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[0.66666667 0.2        0.2        ... 0.6        0.4        0.06666667]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  normalized_data.iloc[:, 1:] = scaler.fit_transform(Alphabets_df.iloc[:, 1:])\n",
      "C:\\Users\\Pooja\\AppData\\Local\\Temp\\ipykernel_4656\\1887860129.py:6: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[0.53333333 0.6        0.46666667 ... 0.33333333 0.53333333 0.53333333]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  normalized_data.iloc[:, 1:] = scaler.fit_transform(Alphabets_df.iloc[:, 1:])\n",
      "C:\\Users\\Pooja\\AppData\\Local\\Temp\\ipykernel_4656\\1887860129.py:6: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[0.         0.13333333 0.2        ... 0.13333333 0.06666667 0.13333333]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  normalized_data.iloc[:, 1:] = scaler.fit_transform(Alphabets_df.iloc[:, 1:])\n",
      "C:\\Users\\Pooja\\AppData\\Local\\Temp\\ipykernel_4656\\1887860129.py:6: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[0.53333333 0.53333333 0.46666667 ... 0.8        0.6        0.46666667]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  normalized_data.iloc[:, 1:] = scaler.fit_transform(Alphabets_df.iloc[:, 1:])\n",
      "C:\\Users\\Pooja\\AppData\\Local\\Temp\\ipykernel_4656\\1887860129.py:6: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[0.         0.26666667 0.2        ... 0.13333333 0.33333333 0.13333333]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  normalized_data.iloc[:, 1:] = scaler.fit_transform(Alphabets_df.iloc[:, 1:])\n",
      "C:\\Users\\Pooja\\AppData\\Local\\Temp\\ipykernel_4656\\1887860129.py:6: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[0.53333333 0.66666667 0.6        ... 0.26666667 0.53333333 0.53333333]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  normalized_data.iloc[:, 1:] = scaler.fit_transform(Alphabets_df.iloc[:, 1:])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>letter</th>\n",
       "      <th>xbox</th>\n",
       "      <th>ybox</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>onpix</th>\n",
       "      <th>xbar</th>\n",
       "      <th>ybar</th>\n",
       "      <th>x2bar</th>\n",
       "      <th>y2bar</th>\n",
       "      <th>xybar</th>\n",
       "      <th>x2ybar</th>\n",
       "      <th>xy2bar</th>\n",
       "      <th>xedge</th>\n",
       "      <th>xedgey</th>\n",
       "      <th>yedge</th>\n",
       "      <th>yedgex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>T</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.533333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>D</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>N</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.533333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>G</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  letter      xbox      ybox  width    height     onpix      xbar      ybar  \\\n",
       "0      T  0.133333  0.533333    0.2  0.333333  0.066667  0.533333  0.866667   \n",
       "1      I  0.333333  0.800000    0.2  0.466667  0.133333  0.666667  0.333333   \n",
       "2      D  0.266667  0.733333    0.4  0.533333  0.400000  0.666667  0.400000   \n",
       "3      N  0.466667  0.733333    0.4  0.400000  0.200000  0.333333  0.600000   \n",
       "4      G  0.133333  0.066667    0.2  0.066667  0.066667  0.533333  0.400000   \n",
       "\n",
       "      x2bar     y2bar     xybar    x2ybar    xy2bar     xedge    xedgey  \\\n",
       "0  0.000000  0.400000  0.400000  0.666667  0.533333  0.000000  0.533333   \n",
       "1  0.333333  0.266667  0.866667  0.200000  0.600000  0.133333  0.533333   \n",
       "2  0.133333  0.400000  0.666667  0.200000  0.466667  0.200000  0.466667   \n",
       "3  0.266667  0.400000  0.266667  0.266667  0.666667  0.400000  0.666667   \n",
       "4  0.400000  0.400000  0.400000  0.333333  0.600000  0.066667  0.466667   \n",
       "\n",
       "      yedge    yedgex  \n",
       "0  0.000000  0.533333  \n",
       "1  0.266667  0.666667  \n",
       "2  0.200000  0.600000  \n",
       "3  0.133333  0.533333  \n",
       "4  0.333333  0.666667  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Normalize the numerical features (excluding the \"letter\" column).\n",
    "scaler = MinMaxScaler()\n",
    "normalized_data = Alphabets_df.copy()\n",
    "normalized_data.iloc[:, 1:] = scaler.fit_transform(Alphabets_df.iloc[:, 1:])\n",
    "\n",
    "# Display the first few rows of the normalized data.\n",
    "normalized_data.head()\n",
    "# The dataset has been normalized, with all numerical features now scaled between 0 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 617
    },
    "id": "V-K8eTBVRlFS",
    "outputId": "f08071c1-f72e-4040-99c5-89989bba186d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "letter    0\n",
       "xbox      0\n",
       "ybox      0\n",
       "width     0\n",
       "height    0\n",
       "onpix     0\n",
       "xbar      0\n",
       "ybar      0\n",
       "x2bar     0\n",
       "y2bar     0\n",
       "xybar     0\n",
       "x2ybar    0\n",
       "xy2bar    0\n",
       "xedge     0\n",
       "xedgey    0\n",
       "yedge     0\n",
       "yedgex    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Alphabets_df.isnull().sum() # Check for missing values. No missing values are present in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-MP3u-mLkzzT"
   },
   "source": [
    "#2.Model Implementation\n",
    "● Construct a basic ANN model using your chosen high-level neural network library. Ensure your model includes at least one hidden layer.             \n",
    "●\tDivide the dataset into training and test sets.                   \n",
    "●\tTrain your model on the training set and then use it to make predictions on the test set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tYFvciGehTpC",
    "outputId": "2b4ac151-9648-4e4e-a914-403faf0c8d9a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Invalid requirement: '#install': Expected package name at the start of dependency specifier\n",
      "    #install\n",
      "    ^\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow #install TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "q65-Qj88rN8c",
    "outputId": "c367c98f-3394-421f-9fc0-3ad5dcd75603"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LabelEncoder\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Sequential\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dense\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mwarnings\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Encode the target labels ('letter') as integers\n",
    "label_encoder = LabelEncoder()\n",
    "normalized_data['letter'] = label_encoder.fit_transform(normalized_data['letter'])\n",
    "\n",
    "\n",
    "X = normalized_data.drop(columns=['letter']) # features.\n",
    "y = normalized_data['letter']                # target.\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42) # Split the dataset into training and test sets (80% train, 20% test)\n",
    "\n",
    "# Build a basic ANN model\n",
    "model = Sequential()\n",
    "\n",
    "# Input layer and one hidden layer\n",
    "model.add(Dense(32, input_dim=X_train.shape[1], activation='relu'))  # Input layer + hidden layer\n",
    "model.add(Dense(16, activation='relu'))                              # Hidden layer\n",
    "model.add(Dense(len(label_encoder.classes_), activation='softmax'))  # Output layer\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "#The sparse categorical cross-entropy loss is similar to categorical cross-entropy, but it is used when the target tensor contains integer class labels instead of one-hot encoded vectors.\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.2, verbose=1)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "loss, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f\"Test Loss: {loss:.4f}\")\n",
    "print(f\"Test Accuracy: {accuracy * 100:.2f}%\")  # Accuracy is printed in percentage format\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o_J-Qe0zyIwj"
   },
   "source": [
    "#3.Hyperparameter Tuning\n",
    "●\tModify various hyperparameters, such as the number of hidden layers, neurons per hidden layer, activation functions, and learning rate, to observe their impact on model performance.                                             \n",
    "●\tAdopt a structured approach like grid search or random search for hyperparameter tuning, documenting your methodology thoroughly.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 654
    },
    "id": "k3E61yNv5JxF",
    "outputId": "aafb886f-2f06-44ec-c4c9-048293985470"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Invalid requirement: '#install': Expected package name at the start of dependency specifier\n",
      "    #install\n",
      "    ^\n"
     ]
    }
   ],
   "source": [
    "!pip install scikeras #install scikeras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "uOm-Tel9B699"
   },
   "outputs": [],
   "source": [
    "#!pip install scikit-learn==1.1.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "y5QOKZQHtCmd"
   },
   "outputs": [],
   "source": [
    "#!pip install tensorflow scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "83UAjnHtDJjQ",
    "outputId": "d65c1ca6-5136-47c7-fd6b-0785c17c21c8"
   },
   "outputs": [],
   "source": [
    "!pip install tensorflow\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "6KMfE6Q0CXyI",
    "outputId": "4b00071e-ec22-4a8f-d36f-b4c39e9b7e0c"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop, SGD\n",
    "\n",
    "# Function to create the model (this allows flexibility for hyperparameter tuning)\n",
    "def create_model(optimizer='adam', activation='relu', neurons=32, hidden_layers=1):\n",
    "    model = Sequential()\n",
    "    # Input layer + hidden layers\n",
    "    model.add(Dense(neurons, input_dim=X_train.shape[1], activation=activation))\n",
    "    for _ in range(hidden_layers - 1):\n",
    "        model.add(Dense(neurons, activation=activation))\n",
    "    # Output layer\n",
    "    model.add(Dense(len(label_encoder.classes_), activation='softmax'))\n",
    "    # Compile the model\n",
    "    model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Encode target labels\n",
    "label_encoder = LabelEncoder()\n",
    "normalized_data['letter'] = label_encoder.fit_transform(normalized_data['letter'])\n",
    "\n",
    "# Split the dataset into features and target\n",
    "X = normalized_data.drop(columns=['letter'])\n",
    "y = normalized_data['letter']\n",
    "\n",
    "# Split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create the KerasClassifier model\n",
    "model = KerasClassifier(build_fn=create_model, verbose=0)\n",
    "\n",
    "# Define random search parameters\n",
    "param_dist = {\n",
    "    'batch_size': [32, 64, 128],\n",
    "    'epochs': [10, 20],\n",
    "    'optimizer': ['adam', 'rmsprop', 'sgd'],\n",
    "    'activation': ['relu', 'tanh'],\n",
    "    'neurons': [16, 32, 64],\n",
    "    'hidden_layers': [1, 2, 3],\n",
    "}\n",
    "\n",
    "# Create RandomizedSearchCV object\n",
    "random_search = RandomizedSearchCV(estimator=model, param_distributions=param_dist, n_iter=10, n_jobs=-1, cv=3)\n",
    "\n",
    "# Execute random search\n",
    "random_result = random_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameters and the best score\n",
    "print(f\"Best parameters: {random_result.best_params_}\")\n",
    "print(f\"Best accuracy: {random_result.best_score_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T-mJ2GnhLeZi"
   },
   "source": [
    "#4.Evaluation\n",
    "●\tEmploy suitable metrics such as accuracy, precision, recall, and F1-score to evaluate your model's performance.                                    \n",
    "●\tDiscuss the performance differences between the model with default hyperparameters and the tuned model, emphasizing the effects of hyperparameter tuning.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6pJ6mLZAO1tM",
    "outputId": "62d7e357-773e-4abf-feec-5e3eb675b5fb"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "\n",
    "# Predict on the test set using the best model from random search\n",
    "y_pred_default = random_search.best_estimator_.predict(X_test)\n",
    "\n",
    "# Check the shape of the predictions\n",
    "print(f\"Shape of predictions: {y_pred_default.shape}\")\n",
    "\n",
    "# Ensure predictions are 2D for argmax (if necessary)\n",
    "if len(y_pred_default.shape) == 1:\n",
    "    y_pred_default = y_pred_default.reshape(-1, 1)\n",
    "\n",
    "# Convert predictions to integer labels\n",
    "#y_pred_default = y_pred_default.argmax(axis=1)\n",
    "\n",
    "# Calculate evaluation metrics for the best model\n",
    "accuracy_default = accuracy_score(y_test, y_pred_default)\n",
    "precision_default = precision_score(y_test, y_pred_default, average='weighted')\n",
    "recall_default = recall_score(y_test, y_pred_default, average='weighted')\n",
    "f1_default = f1_score(y_test, y_pred_default, average='weighted')\n",
    "\n",
    "# Print the classification report for the best model\n",
    "print(\"Best Model Performance:\")\n",
    "print(classification_report(y_test, y_pred_default))\n",
    "\n",
    "print(f\"Accuracy: {accuracy_default}\")\n",
    "print(f\"Precision: {precision_default}\")\n",
    "print(f\"Recall: {recall_default}\")\n",
    "print(f\"F1-Score: {f1_default}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IPiOU01uO35P",
    "outputId": "898e4f0d-00ad-495a-d146-56d42248a150"
   },
   "outputs": [],
   "source": [
    "# Predict on the test set with the tuned model\n",
    "y_pred_tuned = random_search.best_estimator_.predict(X_test)\n",
    "\n",
    "# Check the shape of the predictions\n",
    "print(f\"Shape of predictions: {y_pred_default.shape}\")\n",
    "\n",
    "# Ensure predictions are 2D for argmax (if necessary)\n",
    "if len(y_pred_default.shape) == 1:\n",
    "    y_pred_default = y_pred_default.reshape(-1, 1)\n",
    "\n",
    "# Convert predictions to integer labels\n",
    "#y_pred_tuned = y_pred_tuned.argmax(axis=1)\n",
    "\n",
    "# Calculate evaluation metrics for the tuned model\n",
    "accuracy_tuned = accuracy_score(y_test, y_pred_tuned)\n",
    "precision_tuned = precision_score(y_test, y_pred_tuned, average='weighted')\n",
    "recall_tuned = recall_score(y_test, y_pred_tuned, average='weighted')\n",
    "f1_tuned = f1_score(y_test, y_pred_tuned, average='weighted')\n",
    "\n",
    "# Print the classification report for the tuned model\n",
    "print(\"Tuned Model Performance:\")\n",
    "print(classification_report(y_test, y_pred_tuned))\n",
    "\n",
    "print(f\"Accuracy: {accuracy_tuned}\")\n",
    "print(f\"Precision: {precision_tuned}\")\n",
    "print(f\"Recall: {recall_tuned}\")\n",
    "print(f\"F1-Score: {f1_tuned}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wIA8fgs0QLFV"
   },
   "source": [
    "**Discussing Performance Differences :**                                     \n",
    "\n",
    "Accuracy : Typically, hyperparameter tuning should result in higher accuracy as the model becomes more optimized for the data.                       \n",
    "Precision and Recall : These metrics help in understanding how well the model performs in distinguishing between classes, particularly in cases of imbalanced datasets.                                    \n",
    "F1-Score : This metric is particularly useful when precision and recall are not in balance, giving a better sense of the overall performance.\n",
    "\n",
    "**Example Discussion :**\n",
    "\n",
    "Default Model : The default model may achieve moderate accuracy but could struggle with certain classes, leading to lower precision or recall in some cases.                                                     \n",
    "Tuned Model : With hyperparameter tuning, we expect an increase in accuracy, precision, recall, and F1-score. Hyperparameter tuning improves the model's ability to generalize better on the test data, particularly by optimizing the learning rate, number of layers, or activation functions. This could lead to significant improvements, especially if the initial model was underfitting or overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "ya_-3PQNO_Hb",
    "-MP3u-mLkzzT"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
